---
layout: post
title:  "연구 프로젝트 논문 구현"
date:   2020-05-16 20:14:49 +0900
categories: research machine-learning
---
Machine Learning 을 사용한 IOT DDOS attack 구분 시스템 
----

논문 구현을 위해 필요한 것들 
====

제가 선택한 논문인 [Machine Learning DDoS Detection for consumer Internet Of Things Devices](https://ieeexplore.ieee.org/document/8424629) 에서는 저자가 직접 데이터를 수집하였습니다. 저자가 논문을 쓸 당시에는 IoT DoS 트래픽 데이터는 퍼블릭 데이터가 없어 직접 네트워크를 구축하고 트래픽을 만들어서 어택하고 데이터 수집해야 했습니다. 
다행히 현재는 IOT Dos 트래픽 데이터를 구할 수 있어서 라즈베리 파이등을 사용해 네트워크를 구축하는 단계를 건너 뛸 수 있었습니다.  제가 사용한 데이터는 [ieee-data port 사이트](https://ieee-dataport.org/open-access/iot-network-intrusion-dataset) 에서 다운로드를 하였습니다. 해당 데이터는  스마트 홈 디바이스인 SKT NUGU (NU 100) 와 EZVIZ Wi-Fi Camera (C2C Mini O Plus 1080P) 를 사용하여 수집된 42개의 pcap file입니다. 
dos-synflooding,scan-hostport, scan-portos mirai-udpflooding, mirai-ackflooding mirai-httpflooding, mirai-hostbruteforce 등 다양한 어택들의 pcap 파일이 존재했지만 비교적 detect 가 쉬운 httpflooding 과 benign 을 구분하는 ML 모델을 만들기로 하였습니다.   따라서 benign-dec.pcap 와 mirai-httpflooding-1-dec.pcap 를 사용하였습니다. 

| PCAP Filename | DATE | # of Normal Packet | # of Attack Packet
| ------------- |:-------------:| -----:|
| benign-dec | 5/20/2019 | 137396 | 0
| mirai-httpflooding-1-dec |  8/1/2019 | 13764 | 764

이와 같이 노멀 네트워크 정보를 가진 benign-dec.pcap은 오직 normal packet들로 구성되어있고 mirai-httpflooding-1-dec.pcap은 13764개의  Normal packet 과 764 개의 attack packet으로 구성되어 있습니다. 

Data Preprocessing
===

![alt text](/images/wireshark.png "wireshark")

해당 데이터는 pcap 파일이기 때문에 머신러닝 모델에 쓸 수 있게 csv 파일 포멧으로 바꿔주어야 했습니다. 그러하여 etwork상의 packet을 분석해서 보여주는 무료 오픈 툴인 wireshark의 리눅스 커멘드를 사용하여 csv 파일을 생성하였습니다. 
```
tshark -r benign-dec.pcap  -T fields  -e _ws.col.Protocol -e frame.time_delta  -e frame.len -e tcp.flags  -e tcp.ack -e tcp.len -E header=y -E quote=d -E separator=, -E occurrence=f > benign.csv
```
CSV 를 생성할때 feature 로 사용될 protocol type, frame.time_delta, packet size, ack number 와 length 저장하도록 하였습니다.

```
tshark -r mirai-httpflooding-1-dec.pcap -Y "ip.addr==210.89.164.90" -T fields  -e _ws.col.Protocol -e frame.time_delta  -e frame.len -e tcp.flags  -e tcp.ack -e tcp.len -E header=y -E quote=d -E separator=, -E occurrence=f > attack.csv
```
모든 packet 이 normal 한 benign-dec.pcap과 다르게  mirai-httpflooding-1-dec.pcap 은 attack 과 normal 패킷으로 구성되어 있기 때문에 필터링이 더 필요하였습니다.
데이터 작성자에 의하면 attack packet 은 공통적으로 destination ip 가 210.89.164.90 입니다. 그러하여 -Y "ip.addr==210.89.164.90" 라는 필터를 사용하여 attack packet 만 필터링하여 csv 를 만들었습니다. 

실험 코드와 결과
===
Keras를 사용하여 ML 모델링을 하였으며 Google codelab 환경에서 실행하였습니다. 해당 jupyter notebook은 [github](https://github.com/sjlee2016/sjlee2016.github.io/blob/master/ipynb/ML_model_attack.ipynb)에 업로드하였습니다. 


![alt text](/images/data.png "Data")
benign.csv 와 attack.csv 를 구글 드라이브에 업로드 한 뒤에 
마운트를 시키고 읽어주었습니다.  그 후, column들을 protocol, duration, packetSize, tcp flags, ack, length로 바꿔주었습니다. 

```
attackData['isAttack'] = 1
benignData['isAttack']=0
```
![alt text](/images/data_number.png "Protocol")
benign과 attack 패킷을 합쳐주기전에 해당 패킷이 attack 인지 아닌지 구분하기 위해 isAttack 이라는 column을 생성하였습니다. 공격 패킷이면 isAttack이 1 이며 정상 패킷이면 0을 가집니다. 그리하여 제가 만든 ML모델은 해당 패킷이 isAttack이 0, 1 인지 구분하는 binary classifier입니다. 

그 이후에 benign 과 attack packet 을 합쳐주었고 80%를 train에 사용하고 나머지 20%를 테스트에 사용하였습니다. 따라서 훈련 샘플의 사이즈는 88422, 검증 샘플 사이즈는 22106 그리고 테스트 샘플의 사이즈는 27632 였습니다. 

![alt text](/images/data_table.png "Protocol")


![alt text](/images/protocol_benign.png "Protocol")

```
feature_columns = []
feature_layer_inputs = {}
# numeric cols
for header in ['duration', 'packetSize', 'ack', 'length']:
  feature_columns.append(feature_column.numeric_column(header))
  feature_layer_inputs[header] = tf.keras.Input(shape=(1,), name=header)

# bucketized cols
duration_buckets = feature_column.bucketized_column(duration, boundaries=[0,1])
feature_columns.append(duration_buckets)

# indicator cols
protocol = feature_column.categorical_column_with_vocabulary_list(
      'protocol', ['TCP', 'UDP','TLS', 'ICMP', 'ARP', 'DNS', 'HTTP', 'SSH'])
protocol_one_hot = feature_column.indicator_column(protocol)
feature_columns.append(protocol_one_hot)
feature_layer_inputs['protocol'] = tf.keras.Input(shape=(1,), name='protocol', dtype=tf.string)

# embedding cols
protocol_embedding = feature_column.embedding_column(protocol, dimension=8)
feature_columns.append(protocol_embedding)

# crossed cols
crossed_feature = feature_column.crossed_column([duration_buckets , protocol], hash_bucket_size=1000)
crossed_feature = feature_column.indicator_column(crossed_feature)
feature_columns.append(crossed_feature)

batch_size = 32
train_ds = df_to_dataset(train, batch_size=batch_size)
val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)
test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)

feature_layer = tf.keras.layers.DenseFeatures(feature_columns)
feature_layer_outputs = feature_layer(feature_layer_inputs)

x = layers.Dense(128, activation='relu')(feature_layer_outputs)
x = layers.Dense(64, activation='relu')(x)

baggage_pred = layers.Dense(1, activation='sigmoid')(x)

model = keras.Model(inputs=[v for v in feature_layer_inputs.values()], outputs=baggage_pred)
```

```
model.compile(optimizer=keras.optimizers.RMSprop(learning_rate=1e-3),
              loss='binary_crossentropy',
             metrics=['accuracy'])

model.fit(train_ds,
          validation_data=val_ds,
          epochs=5)
```

![alt text](/images/result.png "Result")


![alt text](/images/protocol_http.png "protocol benign" )


![alt text](/images/packetSize.png "Packet size")



